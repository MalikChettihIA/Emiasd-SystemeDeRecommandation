{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Recommender Systems Lab: Building a Movie Recommendation Engine\n",
        "\n",
        "## Lab Overview\n",
        "\n",
        "In this hands-on session, we'll build a complete movie recommendation system using real data. You'll implement multiple algorithms, evaluate their performance, and understand the business implications of different approaches.\n",
        "\n",
        "**Business Context**: You're consulting for a streaming service looking to increase user engagement through personalized recommendations.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "HLnuCk9iFUDq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup and Imports\n"
      ],
      "metadata": {
        "id": "K-5aVd58Fk8V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from datetime import datetime\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# For data processing and algorithms\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from scipy.sparse import csr_matrix\n",
        "from scipy.sparse.linalg import svds\n",
        "from collections import defaultdict\n",
        "import urllib.request\n",
        "import zipfile\n",
        "import os\n",
        "\n",
        "print(\"‚úÖ Setup complete! Let's build some recommender systems!\")"
      ],
      "metadata": {
        "id": "xdxLfaqWFWKs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## Part 1: Data Loading and Exploration\n",
        "\n",
        "In this section, we'll load the MovieLens dataset and conduct exploratory data analysis to understand user behavior patterns, movie popularity distributions, and data quality. This foundational analysis will inform our recommendation strategy and help identify key business insights about user engagement.\n",
        "\n",
        "#### 1.1 Load the MovieLens Dataset"
      ],
      "metadata": {
        "id": "RpEoJ_AOFuGN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the MovieLens 100K dataset with movie information\n",
        "# Download and extract the dataset\n",
        "url = \"http://files.grouplens.org/datasets/movielens/ml-100k.zip\"\n",
        "urllib.request.urlretrieve(url, \"movielens.zip\")\n",
        "\n",
        "with zipfile.ZipFile(\"movielens.zip\", \"r\") as zip_ref:\n",
        "    zip_ref.extractall(\"movielens\")\n",
        "\n",
        "# Load ratings data\n",
        "ratings_df = pd.read_csv('movielens/ml-100k/u.data', sep='\\t',\n",
        "                        names=['user_id', 'item_id', 'rating', 'timestamp'])\n",
        "ratings_df['timestamp'] = pd.to_datetime(ratings_df['timestamp'], unit='s')\n",
        "\n",
        "# Load movie information for content-based filtering\n",
        "movies_df = pd.read_csv('movielens/ml-100k/u.item', sep='|', encoding='latin-1',\n",
        "                       names=['item_id', 'title', 'release_date', 'video_release_date',\n",
        "                             'imdb_url', 'unknown', 'Action', 'Adventure', 'Animation',\n",
        "                             'Children', 'Comedy', 'Crime', 'Documentary', 'Drama',\n",
        "                             'Fantasy', 'Film-Noir', 'Horror', 'Musical', 'Mystery',\n",
        "                             'Romance', 'Sci-Fi', 'Thriller', 'War', 'Western'])\n",
        "\n",
        "# Extract genres\n",
        "genre_columns = ['Action', 'Adventure', 'Animation', 'Children', 'Comedy', 'Crime',\n",
        "                'Documentary', 'Drama', 'Fantasy', 'Film-Noir', 'Horror', 'Musical',\n",
        "                'Mystery', 'Romance', 'Sci-Fi', 'Thriller', 'War', 'Western']\n",
        "\n",
        "print(f\"üìä Dataset shape: {ratings_df.shape}\")\n",
        "print(f\"üë• Number of users: {ratings_df['user_id'].nunique()}\")\n",
        "print(f\"üé¨ Number of movies: {ratings_df['item_id'].nunique()}\")\n",
        "print(f\"‚≠ê Rating scale: {ratings_df['rating'].min()} to {ratings_df['rating'].max()}\")\n",
        "print(f\"üìÖ Date range: {ratings_df['timestamp'].min()} to {ratings_df['timestamp'].max()}\")\n",
        "print(f\"\\nüè∑Ô∏è Number of genres: {len(genre_columns)}\")"
      ],
      "metadata": {
        "id": "i7RR8jWlFsd-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1.2 Exploratory Data Analysis"
      ],
      "metadata": {
        "id": "h-JhysnFF5N4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Complete the visualization code\n",
        "\n",
        "# 1. Create a bar chart showing how many times each rating value (1-5) appears in the dataset\n",
        "# YOUR CODE HERE\n",
        "\n",
        "# 2. Create a histogram showing the distribution of how many ratings each user has made\n",
        "# YOUR CODE HERE\n",
        "\n",
        "# 3. Create a line plot showing movies ranked by popularity (number of ratings received)\n",
        "# YOUR CODE HERE\n",
        "\n",
        "# 4. Create a bar chart showing how many movies belong to each genre category\n",
        "# YOUR CODE HERE\n"
      ],
      "metadata": {
        "id": "DrkiTYBRFp2Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### üí° Business Insight Questions"
      ],
      "metadata": {
        "id": "edRG1r5jF8uI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Let's analyze some business-relevant patterns\n",
        "\n",
        "# 1. What percentage of users are \"power users\" (>100 ratings)?\n",
        "# YOUR CODE HERE\n",
        "print(f\"üë§ Power users (>100 ratings): {}%\")\n",
        "\n",
        "# 2. What percentage of movies have very few ratings (<10)?\n",
        "# YOUR CODE HERE\n",
        "print(f\"üé¨ Rare movies (<10 ratings): {}%\")\n",
        "\n",
        "# 3. Calculate the percentage of ratings that come from the top 20% most active users\n",
        "# This demonstrates the 80/20 rule in user engagement\n",
        "# YOUR CODE HERE\n",
        "print(f\"üìä Percentage of ratings from top 20% users: {}%\")"
      ],
      "metadata": {
        "id": "RLS6_OYvGAWw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 2: Building Baseline Recommenders\n",
        "\n",
        "Now we'll implement our first recommendation algorithms, starting with simple but effective baseline approaches. These methods provide a foundation for comparison and handle common challenges like cold start problems for new users.\n",
        "\n",
        "#### 2.1 Popularity-Based Recommender"
      ],
      "metadata": {
        "id": "rwYsiuMeGHiz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class PopularityRecommender:\n",
        "    \"\"\"\n",
        "    Simple recommender that suggests the most popular movies.\n",
        "    Good baseline and handles cold start for new users.\n",
        "    \"\"\"\n",
        "    def __init__(self, min_ratings=50):\n",
        "        self.min_ratings = min_ratings\n",
        "        self.popular_movies = None\n",
        "\n",
        "    def fit(self, ratings_df):\n",
        "        # TODO: Implement `fit` method for `PopularityRecommender`\n",
        "        # Steps:\n",
        "        # - Filter movies with minimum ratings\n",
        "        # - Compute movie stats, e.g., mean rating, number of ratings, etc.\n",
        "        # - Combine movie stats into a popularity score\n",
        "        # - Save in `self.popular_movies` the movies ordered by popularity score\n",
        "        #     Note that the `recommend_for_user` method selects the top-n movies from `self.popular_movies`\n",
        "\n",
        "        # YOUR CODE HERE\n",
        "\n",
        "        # Final step\n",
        "        self.popular_movies = ...\n",
        "        return self\n",
        "\n",
        "    def recommend_for_user(self, user_id=None, n=10):\n",
        "        \"\"\"Return top N popular movies (user_id is ignored for popularity-based)\"\"\"\n",
        "        return self.popular_movies.head(n)"
      ],
      "metadata": {
        "id": "PJsVqgX9GN0F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def add_movie_titles(recommendations_df, movies_df):\n",
        "    \"\"\"Helper function to add movie titles to recommendations\"\"\"\n",
        "    return recommendations_df.merge(movies_df[['item_id', 'title']], on='item_id', how='left')"
      ],
      "metadata": {
        "id": "GQDoCcFSIq_y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generate recommendations with the popularity recommender"
      ],
      "metadata": {
        "id": "1i0YCK-MI2RM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pop_rec = PopularityRecommender(min_ratings=50)\n",
        "pop_rec.fit(ratings_df)\n",
        "\n",
        "print(\"üèÜ Top 10 Popular Movies:\")\n",
        "popular_recommendations = pop_rec.recommend_for_user(n=10)\n",
        "\n",
        "# Add movie titles\n",
        "popular_with_titles = add_movie_titles(popular_recommendations, movies_df)\n",
        "print(popular_with_titles)"
      ],
      "metadata": {
        "id": "H_GtJs24Ij-g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## Part 3: Collaborative Filtering\n",
        "\n",
        "In this section, we'll build recommenders based on collaborative filtering, namely user-based collaborative filtering and a more sophisticated approach using matrix factorization (SVD) to discover hidden patterns in user preferences. SVD can uncover latent factors that explain user-item interactions and often provides superior personalization compared to simpler methods.\n",
        "\n",
        "#### 3.1 User-Based Collaborative Filtering"
      ],
      "metadata": {
        "id": "X6USKOW_GQYI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class UserBasedCFRecommender:\n",
        "    def __init__(self, n_similar_users=50):\n",
        "        self.n_similar_users = n_similar_users\n",
        "        self.user_item_matrix = None\n",
        "\n",
        "    def fit(self, ratings_df):\n",
        "        \"\"\"Build user-item matrix from ratings data\"\"\"\n",
        "        self.user_item_matrix = ratings_df.pivot_table(\n",
        "            index='user_id',\n",
        "            columns='item_id',\n",
        "            values='rating'\n",
        "        ).fillna(0)\n",
        "        return self\n",
        "\n",
        "    def recommend_for_user(self, user_id, n=10):\n",
        "        \"\"\"\n",
        "        Recommend movies based on similar users' preferences\n",
        "        \"\"\"\n",
        "        if user_id not in self.user_item_matrix.index:\n",
        "            return pd.DataFrame(columns=['item_id', 'predicted_score'])\n",
        "\n",
        "        # Get the target user's ratings\n",
        "        target_user_ratings = self.user_item_matrix.loc[user_id]\n",
        "\n",
        "        # TODO: Calculate cosine similarity between target user and all other users\n",
        "        # Hint: Use cosine_similarity from sklearn with proper reshaping\n",
        "        # Expected: user_similarities should be a 1D array of similarity scores\n",
        "        # YOUR CODE HERE\n",
        "        user_similarities = ...\n",
        "\n",
        "        # Get indices of most similar users (excluding the user themselves)\n",
        "        similar_users_indices = np.argsort(user_similarities)[::-1][1:self.n_similar_users+1]\n",
        "        similar_users = self.user_item_matrix.index[similar_users_indices]\n",
        "\n",
        "        # Generate recommendations based on what similar users liked\n",
        "        # but the target user hasn't seen\n",
        "        recommendations = defaultdict(float)\n",
        "        for idx, similar_user in enumerate(similar_users):\n",
        "            similarity = user_similarities[similar_users_indices[idx]]\n",
        "            similar_user_ratings = self.user_item_matrix.loc[similar_user]\n",
        "\n",
        "            # Find movies the similar user rated highly but target user hasn't seen\n",
        "            for movie_id, rating in similar_user_ratings.items():\n",
        "                if target_user_ratings[movie_id] == 0 and rating >= 4:\n",
        "                    recommendations[movie_id] += rating * similarity\n",
        "\n",
        "        # Sort and return top N\n",
        "        top_recommendations = sorted(recommendations.items(), key=lambda x: x[1], reverse=True)[:n]\n",
        "        return pd.DataFrame(top_recommendations, columns=['item_id', 'predicted_score'])"
      ],
      "metadata": {
        "id": "EAOkYQTmGRuD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generate recommendations with the user-based CF recommender"
      ],
      "metadata": {
        "id": "Ve5QAzVuJN-P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cf_recommender = UserBasedCFRecommender(n_similar_users=50)\n",
        "cf_recommender.fit(ratings_df)\n",
        "\n",
        "# Test with a sample user\n",
        "sample_user = ratings_df['user_id'].sample(1).iloc[0]\n",
        "print(f\"üë§ Recommendations for User {sample_user}:\")\n",
        "\n",
        "# Get recommendations using the class method\n",
        "user_cf_recs = cf_recommender.recommend_for_user(sample_user, n=10)\n",
        "# Add movie titles\n",
        "user_cf_recs_with_titles = add_movie_titles(user_cf_recs, movies_df)\n",
        "print(user_cf_recs_with_titles)"
      ],
      "metadata": {
        "id": "knOkz755JNar"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.2 Matrix Factorization with SVD"
      ],
      "metadata": {
        "id": "wLV_STtZJ-gu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SVDRecommender:\n",
        "    \"\"\"\n",
        "    Efficient SVD-based recommender using scipy's optimized implementation\n",
        "    \"\"\"\n",
        "    def __init__(self, n_factors=50):\n",
        "        self.n_factors = n_factors\n",
        "        self.user_item_matrix = None\n",
        "        self.predicted_ratings = None\n",
        "        self.user_means = None\n",
        "        self.user_ids = None\n",
        "        self.item_ids = None\n",
        "\n",
        "    def fit(self, train_df):\n",
        "        \"\"\"Train SVD model and store reference data\"\"\"\n",
        "        self.ratings_df = train_df\n",
        "\n",
        "        # Create user-item matrix\n",
        "        self.user_item_matrix = train_df.pivot_table(\n",
        "            index='user_id',\n",
        "            columns='item_id',\n",
        "            values='rating'\n",
        "        )\n",
        "\n",
        "        # Store indices for lookup\n",
        "        self.user_ids = self.user_item_matrix.index\n",
        "        self.item_ids = self.user_item_matrix.columns\n",
        "\n",
        "        # Fill NaN and normalize\n",
        "        matrix_filled = self.user_item_matrix.fillna(0)\n",
        "        self.user_means = np.mean(matrix_filled.values, axis=1)\n",
        "        matrix_normalized = matrix_filled.values - self.user_means.reshape(-1, 1)\n",
        "\n",
        "        # Apply SVD\n",
        "        U, sigma, Vt = svds(csr_matrix(matrix_normalized), k=self.n_factors)\n",
        "        sigma = np.diag(sigma)\n",
        "\n",
        "        # Reconstruct ratings matrix\n",
        "        self.predicted_ratings = np.dot(np.dot(U, sigma), Vt) + self.user_means.reshape(-1, 1)\n",
        "\n",
        "        return self\n",
        "\n",
        "    def predict(self, user_id, item_id):\n",
        "        \"\"\"Predict rating for user-item pair(s)\"\"\"\n",
        "        if isinstance(user_id, (list, np.ndarray)):\n",
        "            return [self._predict_single(u, i) for u, i in zip(user_id, item_id)]\n",
        "        else:\n",
        "            return self._predict_single(user_id, item_id)\n",
        "\n",
        "    def _predict_single(self, user_id, item_id):\n",
        "        \"\"\"Predict rating for single user-item pair\"\"\"\n",
        "        try:\n",
        "            user_idx = self.user_ids.get_loc(user_id)\n",
        "            item_idx = self.item_ids.get_loc(item_id)\n",
        "            prediction = self.predicted_ratings[user_idx, item_idx]\n",
        "            return np.clip(prediction, 1, 5)\n",
        "        except KeyError:\n",
        "            # Return global mean for unknown users/items\n",
        "            return np.mean(self.user_means) + 3  # Reasonable default\n",
        "\n",
        "    def recommend_for_user(self, user_id, n=10):\n",
        "        \"\"\"Get top N recommendations for a user\"\"\"\n",
        "        if user_id not in self.user_ids:\n",
        "            return pd.DataFrame(columns=['item_id', 'predicted_rating', 'title'])\n",
        "\n",
        "        # Get user index\n",
        "        user_idx = self.user_ids.get_loc(user_id)\n",
        "        user_predictions = self.predicted_ratings[user_idx]\n",
        "\n",
        "        # Get items the user has already rated (need to store ratings_df)\n",
        "        if hasattr(self, 'ratings_df'):\n",
        "            user_items = self.ratings_df[self.ratings_df['user_id'] == user_id]['item_id'].values\n",
        "        else:\n",
        "            user_items = []\n",
        "\n",
        "        # Create recommendations\n",
        "        recommendations = []\n",
        "        for idx, item_id in enumerate(self.item_ids):\n",
        "            if item_id not in user_items:\n",
        "                recommendations.append((item_id, user_predictions[idx]))\n",
        "\n",
        "        # Sort and return top N\n",
        "        recommendations.sort(key=lambda x: x[1], reverse=True)\n",
        "        rec_df = pd.DataFrame(recommendations[:n], columns=['item_id', 'predicted_rating'])\n",
        "        return rec_df"
      ],
      "metadata": {
        "id": "HCz4OGeRKB43"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generate recommendations with the SVD recommender"
      ],
      "metadata": {
        "id": "f9vUXhThKHCR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Usage\n",
        "print(\"üîß Training SVD model...\")\n",
        "train_data = ratings_df.sample(frac=0.8, random_state=42)\n",
        "test_data = ratings_df.drop(train_data.index)\n",
        "\n",
        "svd_model = SVDRecommender(n_factors=50)\n",
        "svd_model.fit(train_data)\n",
        "print(\"‚úÖ SVD model trained!\")\n",
        "\n",
        "# Test recommendations\n",
        "test_user = ratings_df['user_id'].sample(1).iloc[0]\n",
        "print(f\"üéØ SVD Recommendations for User {test_user}:\")\n",
        "\n",
        "svd_recommendations = svd_model.recommend_for_user(test_user, n=10)\n",
        "svd_recommendations = add_movie_titles(svd_recommendations, movies_df)\n",
        "\n",
        "print(svd_recommendations)"
      ],
      "metadata": {
        "id": "iBtOg04NKGe1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## Part 4: Content-Based Filtering\n",
        "\n",
        "In this section, we'll build recommenders that leverage movie characteristics like genres and release year to find similar content. Content-based approaches excel at recommending items similar to what users have already enjoyed and can handle new items effectively.\n",
        "\n",
        "#### 4.1 Feature Engineering for Movies"
      ],
      "metadata": {
        "id": "1DllhEqfGTPM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare content features for movies\n",
        "def prepare_movie_features(movies_df):\n",
        "    \"\"\"\n",
        "    Create feature vectors for movies based on genres and other attributes\n",
        "    \"\"\"\n",
        "    movies_df = movies_df.copy()\n",
        "    # Genre features (already binary)\n",
        "    genre_features = movies_df[genre_columns].values\n",
        "\n",
        "    # Extract year from release date\n",
        "    movies_df['year'] = pd.to_datetime(movies_df['release_date'], errors='coerce').dt.year\n",
        "    movies_df['year'].fillna(movies_df['year'].median(), inplace=True)\n",
        "\n",
        "    # Normalize year to 0-1 range\n",
        "    min_year = movies_df['year'].min()\n",
        "    max_year = movies_df['year'].max()\n",
        "    movies_df['year_normalized'] = (movies_df['year'] - min_year) / (max_year - min_year)\n",
        "\n",
        "    # Combine all features\n",
        "    feature_matrix = np.column_stack([\n",
        "        genre_features,\n",
        "        movies_df['year_normalized'].values.reshape(-1, 1)\n",
        "    ])\n",
        "\n",
        "    return feature_matrix, movies_df\n",
        "\n",
        "# Prepare features\n",
        "movie_features, movies_enhanced = prepare_movie_features(movies_df)\n",
        "print(f\"üìê Movie feature matrix shape: {movie_features.shape}\")\n",
        "print(f\"üìä Features include: {len(genre_columns)} genres + 1 year feature\")"
      ],
      "metadata": {
        "id": "UguoWerHGX7r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 4.2 Content-Based Item Similarity"
      ],
      "metadata": {
        "id": "sWBwDghTGaea"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ContentBasedRecommender:\n",
        "    def __init__(self, movies_df, movie_features):\n",
        "        self.movies_df = movies_df\n",
        "        self.movie_features = movie_features\n",
        "        self.item_similarities = None\n",
        "        self.ratings_df = None\n",
        "\n",
        "    def fit(self, ratings_df=None):\n",
        "        \"\"\"Calculate item-item similarities and store ratings data\"\"\"\n",
        "        if ratings_df is not None:\n",
        "            self.ratings_df = ratings_df\n",
        "\n",
        "        # TODO: Compute item similarities between all movies\n",
        "        # Hint: Use cosine similarity between `self.movie_features`, and store the result in `self.item_similarities`\n",
        "        # YOUR CODE HERE\n",
        "        return self\n",
        "\n",
        "    def get_similar_items(self, item_id, n=10):\n",
        "        \"\"\"Find n most similar items to the given item\"\"\"\n",
        "        if item_id not in self.movies_df['item_id'].values:\n",
        "            return pd.DataFrame(columns=['item_id', 'title', 'similarity_score'])\n",
        "\n",
        "        # Get index of the movie\n",
        "        idx = self.movies_df[self.movies_df['item_id'] == item_id].index[0]\n",
        "\n",
        "        # Get similarity scores and sort\n",
        "        sim_scores = list(enumerate(self.item_similarities[idx]))\n",
        "        sim_scores.sort(key=lambda x: x[1], reverse=True)\n",
        "\n",
        "        # Get top N similar movies (excluding itself)\n",
        "        similar_indices = [i[0] for i in sim_scores[1:n+1]]\n",
        "        similar_movies = self.movies_df.iloc[similar_indices][['item_id', 'title']].copy()\n",
        "        similar_movies['similarity_score'] = [i[1] for i in sim_scores[1:n+1]]\n",
        "\n",
        "        return similar_movies\n",
        "\n",
        "    def recommend_for_user(self, user_id, n=10):\n",
        "        \"\"\"Recommend items for a user (now uses stored ratings_df)\"\"\"\n",
        "        if self.ratings_df is None:\n",
        "            raise ValueError(\"No ratings data available. Call fit(ratings_df) first.\")\n",
        "\n",
        "        # Get user's rated movies\n",
        "        user_movies = self.ratings_df[self.ratings_df['user_id'] == user_id]\n",
        "        if len(user_movies) == 0:\n",
        "            return pd.DataFrame(columns=['item_id', 'content_score', 'title'])\n",
        "\n",
        "        # Get highly rated movies by the user\n",
        "        liked_movies = user_movies[user_movies['rating'] >= 4]['item_id'].values\n",
        "        if len(liked_movies) == 0:\n",
        "            liked_movies = user_movies.nlargest(3, 'rating')['item_id'].values\n",
        "\n",
        "        # Find similar movies to what the user liked\n",
        "        # Aggregate similarity scores across all liked movies\n",
        "        recommendations = defaultdict(float)\n",
        "\n",
        "        for movie_id in liked_movies:\n",
        "            if movie_id in self.movies_df['item_id'].values:\n",
        "                similar_movies = self.get_similar_items(movie_id, n=20)\n",
        "                for _, row in similar_movies.iterrows():\n",
        "                    # Don't recommend movies the user has already seen\n",
        "                    if row['item_id'] not in user_movies['item_id'].values:\n",
        "                        recommendations[row['item_id']] += row['similarity_score']\n",
        "\n",
        "        # Sort and get top N\n",
        "        top_recommendations = sorted(recommendations.items(), key=lambda x: x[1], reverse=True)[:n]\n",
        "        result_df = pd.DataFrame(top_recommendations, columns=['item_id', 'content_score'])\n",
        "        result_df = result_df.merge(self.movies_df[['item_id', 'title']], on='item_id')\n",
        "\n",
        "        return result_df\n"
      ],
      "metadata": {
        "id": "rf2B-A2TGcC7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generate recommendations with the content-based recommender"
      ],
      "metadata": {
        "id": "I_M-75TEKrQS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create and test content-based recommender\n",
        "content_rec = ContentBasedRecommender(movies_enhanced, movie_features)\n",
        "content_rec.fit(ratings_df)"
      ],
      "metadata": {
        "id": "0VAmuRMPKrcP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test: Find similar movies to Star Wars\n",
        "star_wars_id = movies_df[movies_df['title'].str.contains('Star Wars', case=False)]['item_id'].iloc[0]\n",
        "print(f\"üé¨ Movies similar to '{movies_df[movies_df['item_id']==star_wars_id]['title'].iloc[0]}':\")\n",
        "print(content_rec.get_similar_items(star_wars_id, n=10))"
      ],
      "metadata": {
        "id": "diT0WNkrOocR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test: Recommendations for a user\n",
        "print(f\"\\nüìö Content-based recommendations for User {sample_user}:\")\n",
        "print(content_rec.recommend_for_user(sample_user, n=10))"
      ],
      "metadata": {
        "id": "SH91x2WkOpu0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 4.3 Analyzing Content Patterns"
      ],
      "metadata": {
        "id": "sftKmIUQGdiv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize content similarity\n",
        "def visualize_genre_similarity(content_rec, sample_size=50):\n",
        "    \"\"\"Visualize similarity between movies based on content\"\"\"\n",
        "    # Sample movies for visualization\n",
        "    sample_indices = np.random.choice(len(movies_df), sample_size, replace=False)\n",
        "    sample_similarities = content_rec.item_similarities[sample_indices][:, sample_indices]\n",
        "\n",
        "    # Create labels with movie titles (truncated)\n",
        "    sample_movies = movies_df.iloc[sample_indices]\n",
        "    labels = [title[:20] + '...' if len(title) > 20 else title\n",
        "              for title in sample_movies['title'].values]\n",
        "\n",
        "    # Plot heatmap\n",
        "    plt.figure(figsize=(12, 10))\n",
        "    sns.heatmap(sample_similarities, cmap='YlOrRd',\n",
        "                xticklabels=labels, yticklabels=labels,\n",
        "                cbar_kws={'label': 'Content Similarity'})\n",
        "    plt.title('Content Similarity Matrix (Sample of Movies)')\n",
        "    plt.xticks(rotation=90)\n",
        "    plt.yticks(rotation=0)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "visualize_genre_similarity(content_rec, sample_size=30)"
      ],
      "metadata": {
        "id": "spPaWFTvGfz0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## Part 5: Evaluation with Precision and Recall\n",
        "\n",
        "Proper evaluation is crucial for understanding which algorithms work best for your specific use case. In this section, we'll implement standard recommendation metrics and compare our different approaches to determine their relative strengths and weaknesses.\n",
        "\n",
        "#### 5.1 Implementing Precision@K and Recall@K"
      ],
      "metadata": {
        "id": "PtjOQokUGsxL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def precision_recall_at_k(actual_items, predicted_items, k=10):\n",
        "    \"\"\"\n",
        "    Calculate precision and recall at k for a single user\n",
        "    \"\"\"\n",
        "    predicted_items_at_k = predicted_items[:k]\n",
        "\n",
        "    # TODO: Implement Precision@K\n",
        "    # YOUR CODE HERE\n",
        "    precision = ...\n",
        "\n",
        "    # TODO: Implement Recall@K\n",
        "    # YOUR CODE HERE\n",
        "    recall = ...\n",
        "\n",
        "    return precision, recall\n",
        "\n",
        "def evaluate_recommender_precision_recall(recommender, test_data, k_values=[5, 10, 20]):\n",
        "    \"\"\"Evaluate a recommender system using precision and recall at different K values\"\"\"\n",
        "    results = {}\n",
        "    test_users = test_data['user_id'].unique()[:100]  # Sample for speed\n",
        "\n",
        "    for k in k_values:\n",
        "        precisions, recalls = [], []\n",
        "\n",
        "        for user_id in test_users:\n",
        "            # Get user's highly-rated test items\n",
        "            user_test_items = test_data[\n",
        "                (test_data['user_id'] == user_id) & (test_data['rating'] >= 4)\n",
        "            ]['item_id'].values\n",
        "\n",
        "            if len(user_test_items) == 0:\n",
        "                continue\n",
        "\n",
        "            # Get recommendations\n",
        "            try:\n",
        "                recommendations = recommender.recommend_for_user(user_id, n=k)\n",
        "                predicted_items = recommendations['item_id'].values if len(recommendations) > 0 else []\n",
        "            except:\n",
        "                continue\n",
        "\n",
        "            # Calculate metrics\n",
        "            precision, recall = precision_recall_at_k(user_test_items, predicted_items, k)\n",
        "            precisions.append(precision)\n",
        "            recalls.append(recall)\n",
        "\n",
        "        # Store results\n",
        "        if precisions:\n",
        "            results[f'precision@{k}'] = np.mean(precisions)\n",
        "            results[f'recall@{k}'] = np.mean(recalls)\n",
        "            prec, rec = results[f'precision@{k}'], results[f'recall@{k}']\n",
        "            results[f'f1@{k}'] = 2 * prec * rec / (prec + rec) if (prec + rec) > 0 else 0\n",
        "        else:\n",
        "            results[f'precision@{k}'] = results[f'recall@{k}'] = results[f'f1@{k}'] = 0.0\n",
        "\n",
        "    return results"
      ],
      "metadata": {
        "id": "_IpBlMxqGsUA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Re-train models on train data\n",
        "pop_rec = PopularityRecommender(min_ratings=50).fit(train_data)\n",
        "content_rec = ContentBasedRecommender(movies_enhanced, movie_features).fit(train_data)\n",
        "cf_rec = UserBasedCFRecommender(n_similar_users=50).fit(train_data)\n",
        "svd_rec = SVDRecommender(n_factors=50).fit(train_data)\n",
        "\n",
        "print(\"‚úÖ All models trained!\")"
      ],
      "metadata": {
        "id": "yB9-pAlwLcNU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"üìä Evaluating algorithms with Precision@K and Recall@K:\\n\")\n",
        "\n",
        "algorithms = {\n",
        "    'Popularity-Based': pop_rec,\n",
        "    'Content-Based': content_rec,\n",
        "    'User-Based CF': cf_rec,\n",
        "    'SVD (Matrix Factorization)': svd_rec\n",
        "}\n",
        "\n",
        "evaluation_results = {}\n",
        "for name, recommender in algorithms.items():\n",
        "    print(f\"Evaluating {name}...\")\n",
        "    results = evaluate_recommender_precision_recall(recommender, test_data, k_values=[5, 10, 20])\n",
        "    evaluation_results[name] = results\n",
        "    print(f\"{name}: Precision@10={results['precision@10']:.3f}, Recall@10={results['recall@10']:.3f}\")"
      ],
      "metadata": {
        "id": "kB1l8ZgaLcg1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 5.2 Comprehensive Evaluation Framework"
      ],
      "metadata": {
        "id": "PDtESOnNG3H4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_recommender_comprehensive(recommender, test_data, k_values=[5, 10, 20]):\n",
        "    \"\"\"\n",
        "    Evaluate recommender on multiple metrics and different K values\n",
        "    \"\"\"\n",
        "    results = defaultdict(dict)\n",
        "\n",
        "    # Get unique users in test set\n",
        "    test_users = test_data['user_id'].unique()[:100]  # Sample for speed\n",
        "\n",
        "    for k in k_values:\n",
        "        all_precisions = []\n",
        "        all_recalls = []\n",
        "        recommended_items = set()\n",
        "\n",
        "        for user_id in test_users:\n",
        "            # Get user's test items (items they rated highly)\n",
        "            user_test_items = test_data[\n",
        "                (test_data['user_id'] == user_id) &\n",
        "                (test_data['rating'] >= 4)\n",
        "            ]['item_id'].values\n",
        "\n",
        "            if len(user_test_items) == 0:\n",
        "                continue\n",
        "\n",
        "            # Get recommendations\n",
        "            try:\n",
        "                recs = recommender.recommend_for_user(user_id, n=k)\n",
        "                rec_items = recs['item_id'].values\n",
        "            except Exception as e:\n",
        "                # Skip if recommender fails (e.g., user not in training data)\n",
        "                continue\n",
        "\n",
        "            # Calculate metrics\n",
        "            hits = len(set(rec_items) & set(user_test_items))\n",
        "            precision = hits / k if k > 0 else 0\n",
        "            recall = hits / len(user_test_items) if len(user_test_items) > 0 else 0\n",
        "\n",
        "            all_precisions.append(precision)\n",
        "            all_recalls.append(recall)\n",
        "            recommended_items.update(rec_items)\n",
        "\n",
        "        # Store results\n",
        "        results[k]['precision'] = np.mean(all_precisions) if all_precisions else 0\n",
        "        results[k]['recall'] = np.mean(all_recalls) if all_recalls else 0\n",
        "        results[k]['f1'] = 2 * results[k]['precision'] * results[k]['recall'] / \\\n",
        "                          (results[k]['precision'] + results[k]['recall']) \\\n",
        "                          if (results[k]['precision'] + results[k]['recall']) > 0 else 0\n",
        "        results[k]['coverage'] = len(recommended_items) / len(test_data['item_id'].unique())\n",
        "\n",
        "    return dict(results)"
      ],
      "metadata": {
        "id": "kMVoidU9G0Sp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate all recommenders\n",
        "print(\"\\nüìä Comprehensive Evaluation Results:\\n\")\n",
        "\n",
        "# Use your trained recommenders with unified interface\n",
        "recommenders = {\n",
        "    'Popularity': pop_rec,\n",
        "    'Content-Based': content_rec,\n",
        "    'CF User-Based': cf_rec,\n",
        "    'SVD Matrix Factorization': svd_rec\n",
        "}\n",
        "\n",
        "for name, rec in recommenders.items():\n",
        "    print(f\"\\n{name} Recommender:\")\n",
        "    results = evaluate_recommender_comprehensive(rec, test_data)\n",
        "\n",
        "    # Display results in a nice table\n",
        "    metrics_df = pd.DataFrame(results).T\n",
        "    metrics_df.index.name = 'K'\n",
        "    print(metrics_df.round(3))"
      ],
      "metadata": {
        "id": "kmUgxWG_LuWJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 5.3 Visualizing Performance Trade-offs"
      ],
      "metadata": {
        "id": "QPsfnWuSG675"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_precision_recall_curves(recommenders_results):\n",
        "    \"\"\"\n",
        "    Plot precision-recall curves for different recommenders\n",
        "    \"\"\"\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
        "\n",
        "    # Plot 1: Precision and Recall vs K\n",
        "    k_values = [5, 10, 20]\n",
        "\n",
        "    # Use the evaluation results we already have\n",
        "    for name, results in evaluation_results.items():\n",
        "        precisions = [results[f'precision@{k}'] for k in k_values]\n",
        "        recalls = [results[f'recall@{k}'] for k in k_values]\n",
        "\n",
        "        ax1.plot(k_values, precisions, marker='o', label=f'{name} (Precision)')\n",
        "        ax1.plot(k_values, recalls, marker='s', linestyle='--', label=f'{name} (Recall)')\n",
        "\n",
        "    ax1.set_xlabel('K (Number of Recommendations)')\n",
        "    ax1.set_ylabel('Score')\n",
        "    ax1.set_title('Precision and Recall vs K')\n",
        "    ax1.legend()\n",
        "    ax1.grid(True)\n",
        "\n",
        "    # Plot 2: Precision vs Recall trade-off\n",
        "    for name, results in evaluation_results.items():\n",
        "        k_values_extended = [5, 10, 15, 20]\n",
        "        precisions = []\n",
        "        recalls = []\n",
        "\n",
        "        for k in k_values_extended:\n",
        "            if f'precision@{k}' in results:\n",
        "                precisions.append(results[f'precision@{k}'])\n",
        "                recalls.append(results[f'recall@{k}'])\n",
        "\n",
        "        ax2.plot(recalls, precisions, marker='o', label=name)\n",
        "\n",
        "    ax2.set_xlabel('Recall')\n",
        "    ax2.set_ylabel('Precision')\n",
        "    ax2.set_title('Precision-Recall Trade-off')\n",
        "    ax2.legend()\n",
        "    ax2.grid(True)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "W3ZbaXEiG_YL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_precision_recall_curves(evaluation_results)"
      ],
      "metadata": {
        "id": "UY2QFUDjZVmL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## Part 6: Production Considerations\n",
        "\n",
        "Moving beyond algorithmic metrics, this section focuses on preparing systems for production deployment. We'll build a production-ready service with proper error handling and monitoring.\n",
        "\n",
        "#### 6.1 Production Deployment Considerations\n"
      ],
      "metadata": {
        "id": "h_xYpjehHBQh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class RecommendationService:\n",
        "    \"\"\"\n",
        "    Production-ready recommendation service with caching and monitoring\n",
        "    \"\"\"\n",
        "    def __init__(self, models_dict, movies_df):\n",
        "        self.models = models_dict\n",
        "        self.movies_df = movies_df\n",
        "        self.cache = {}\n",
        "        self.metrics = defaultdict(int)\n",
        "\n",
        "    def get_recommendations(self, user_id, algorithm='content', n=10, use_cache=True):\n",
        "        \"\"\"\n",
        "        Get recommendations with fallback strategies\n",
        "        \"\"\"\n",
        "        start_time = datetime.now()\n",
        "\n",
        "        # TODO: Implement caching, if `use_cache` is True\n",
        "        # 1. Create cache key from user_id, algorithm, and n\n",
        "        # 2. Check if key exists in self.cache\n",
        "        # 3. Update cache hit/miss metrics, under `cache['cache_hits']` and `cache['cache_misses']`\n",
        "        # 4. Return cached result if available\n",
        "        # YOUR CODE HERE\n",
        "\n",
        "        # If result not available in cache, compute recommendations\n",
        "        try:\n",
        "            if algorithm in self.models:\n",
        "                recs = self.models[algorithm].recommend_for_user(user_id, n=n)\n",
        "            else:\n",
        "                raise ValueError(f\"Unknown algorithm: {algorithm}\")\n",
        "        except Exception as e:\n",
        "            # Fallback to popularity\n",
        "            self.metrics['fallbacks'] += 1\n",
        "            recs = self.models['popularity'].recommend_for_user(user_id, n=n)\n",
        "\n",
        "        # Add movie titles if not present\n",
        "        if len(recs) > 0:\n",
        "            recs = add_movie_titles(recs, movies_df)\n",
        "\n",
        "        # TODO: Cache computed recommendations, if `use_cache` is True\n",
        "        # YOUR CODE HERE\n",
        "\n",
        "        # Record metrics\n",
        "        response_time = (datetime.now() - start_time).total_seconds()\n",
        "        self.metrics['total_requests'] += 1\n",
        "        self.metrics['avg_response_time'] = (\n",
        "            (self.metrics['avg_response_time'] * (self.metrics['total_requests'] - 1) + response_time)\n",
        "            / self.metrics['total_requests']\n",
        "        )\n",
        "\n",
        "        return recs\n",
        "\n",
        "    def get_metrics_summary(self):\n",
        "        \"\"\"Get service metrics\"\"\"\n",
        "        return {\n",
        "            'total_requests': self.metrics['total_requests'],\n",
        "            'cache_hit_rate': self.metrics['cache_hits'] / self.metrics['total_requests']\n",
        "                             if self.metrics['total_requests'] > 0 else 0,\n",
        "            'fallback_rate': self.metrics['fallbacks'] / self.metrics['total_requests']\n",
        "                            if self.metrics['total_requests'] > 0 else 0,\n",
        "            'avg_response_time_ms': self.metrics['avg_response_time'] * 1000\n",
        "        }"
      ],
      "metadata": {
        "id": "vUUqzpG7HIa0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "service = RecommendationService({\n",
        "    'content': content_rec,\n",
        "    'popularity': pop_rec\n",
        "}, movies_df)\n",
        "\n",
        "# Simulate production usage\n",
        "print(\"\\nüöÄ Simulating Production Usage:\\n\")\n",
        "\n",
        "# Different user scenarios\n",
        "test_scenarios = [\n",
        "    {'user_id': 1, 'algorithm': 'content'},     # Normal user\n",
        "    {'user_id': 1, 'algorithm': 'content'},     # Cached request\n",
        "    {'user_id': 50, 'algorithm': 'popularity'}, # Popularity-based\n",
        "    {'user_id': 9999, 'algorithm': 'content'},  # New user (will fallback)\n",
        "]\n",
        "\n",
        "for scenario in test_scenarios:\n",
        "    recs = service.get_recommendations(**scenario)\n",
        "    print(f\"User {scenario['user_id']} ({scenario['algorithm']}): {len(recs)} recommendations\")\n",
        "\n",
        "print(\"\\nüìä Service Metrics:\")\n",
        "for metric, value in service.get_metrics_summary().items():\n",
        "    if 'rate' in metric:\n",
        "        print(f\"  {metric}: {value:.2%}\")\n",
        "    elif 'time' in metric:\n",
        "        print(f\"  {metric}: {value:.2f}\")\n",
        "    else:\n",
        "        print(f\"  {metric}: {value}\")"
      ],
      "metadata": {
        "id": "5ZBWLQZEL3Zh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 7: Key Takeaways and Discussion\n",
        "\n",
        "Finally, we'll synthesize our findings into actionable business recommendations and strategic insights. This section provides a framework for choosing the right approach for different scenarios and discusses important considerations for real-world implementation.\n",
        "\n",
        "#### 7.1 Algorithm Comparison Summary"
      ],
      "metadata": {
        "id": "9pNbEkHtHMQ6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a comprehensive comparison\n",
        "print(\"üéØ ALGORITHM COMPARISON SUMMARY:\\n\")\n",
        "\n",
        "comparison_data = {\n",
        "    'Algorithm': ['Popularity', 'Content-Based', 'User-Based CF', 'SVD (Matrix Factorization)'],\n",
        "    'Cold Start (New Users)': ['‚úÖ Excellent', '‚úÖ Excellent', '‚ùå Poor', '‚ùå Poor'],\n",
        "    'Cold Start (New Items)': ['‚ùå Poor', '‚úÖ Excellent', '‚ùå Poor', '‚ùå Poor'],\n",
        "    'Scalability': ['‚úÖ Excellent', '‚úÖ Good', '‚ö†Ô∏è Moderate', '‚úÖ Good'],\n",
        "    'Interpretability': ['‚úÖ High', '‚úÖ High', '‚ö†Ô∏è Moderate', '‚ùå Low'],\n",
        "    'Personalization': ['‚ùå None', '‚ö†Ô∏è Moderate', '‚úÖ High', '‚úÖ High'],\n",
        "    'Data Requirements': ['Low', 'Item Features', 'User-Item Ratings', 'User-Item Ratings']\n",
        "}\n",
        "\n",
        "comparison_df = pd.DataFrame(comparison_data)\n",
        "print(comparison_df.to_string(index=False))"
      ],
      "metadata": {
        "id": "_YzSA9nZHOON"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 7.2 Business Recommendations\n"
      ],
      "metadata": {
        "id": "58BNSO68HQmf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nüìã KEY BUSINESS RECOMMENDATIONS:\\n\")\n",
        "\n",
        "recommendations = [\n",
        "    \"1. üöÄ Start Simple: Begin with popularity-based recommendations as a baseline\",\n",
        "    \"2. üéØ Hybrid Approach: Combine content-based for new items with CF for personalization\",\n",
        "    \"3. üìä Measure Everything: Track both algorithmic metrics (precision/recall) and business KPIs\",\n",
        "    \"4. üîÑ Continuous Improvement: A/B test different algorithms and parameters\",\n",
        "    \"5. ‚ö° Performance Matters: Cache recommendations and pre-compute when possible\",\n",
        "    \"6. üé® Diversity is Key: Don't just optimize for accuracy - consider novelty and diversity\",\n",
        "    \"7. üõ°Ô∏è Plan for Failures: Always have a fallback strategy (e.g., popularity)\"\n",
        "]\n",
        "\n",
        "for rec in recommendations:\n",
        "    print(rec)\n",
        "\n",
        "print(\"\\nüí≠ DISCUSSION QUESTIONS:\")\n",
        "questions = [\n",
        "    \"- How would you handle recommendations for a brand new streaming service with no data?\",\n",
        "    \"- What additional features could improve content-based recommendations?\",\n",
        "    \"- How do you balance exploitation (recommending sure hits) vs exploration (discovering new content)?\",\n",
        "    \"- How would you detect and mitigate filter bubbles?\"\n",
        "]\n",
        "\n",
        "for question in questions:\n",
        "    print(question)"
      ],
      "metadata": {
        "id": "ERtIc7b5HRNP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### üèÅ Lab Complete!\n"
      ],
      "metadata": {
        "id": "PNOjTGO0HWzR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\"\"\n",
        "üéâ Congratulations! You've built a complete recommendation system!\n",
        "\n",
        "‚úÖ What you've accomplished:\n",
        "- Analyzed real user behavior data\n",
        "- Implemented popularity-based, content-based, and collaborative filtering\n",
        "- Evaluated algorithms using precision and recall metrics\n",
        "- Considered production deployment challenges\n",
        "- Analyzed business impact\n",
        "\n",
        "üìö Next steps:\n",
        "1. Try combining content-based and collaborative filtering in a hybrid approach\n",
        "2. Experiment with deep learning methods (neural collaborative filtering)\n",
        "3. Add contextual features (time of day, device type)\n",
        "4. Implement online learning for real-time adaptation\n",
        "\"\"\")"
      ],
      "metadata": {
        "id": "4LL-yIfKHXYB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SPoSiXCcDKFd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}